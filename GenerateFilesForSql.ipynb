{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates Files For Database\n",
    "\n",
    "The aim of this notebook is by using Obase Version 1's files, generating proper files for Obase Version 2 Database. \n",
    "\n",
    "Basically, the functions in this notebook generate 3 main files to the txtFiles directory:\n",
    "    * CustomerMapping.txt\n",
    "    * ItemMapping.txt\n",
    "    * SalesTensor.txt\n",
    "    \n",
    "In order to generate these files, we need to get the following data files from Obase Version 1 and put them into the originalFiles directory. \n",
    "    * 81_7_24_7269_3392_Customers.txt\n",
    "    * 81_7_24_7269_3392_Items.txt\n",
    "    * 81_7_24_7269_3392_ItemsDs.txt\n",
    "    * 81_7_24_7269_3392_Tensor.txt\n",
    "\n",
    "#### CustomerMapping.txt\n",
    "In the dataset provided by the Obase company, there is no order of customer id values. Values vary. But in our implementation, we need to represent customers by sequential values, from 0 to N (number of customers-1), which we named as CustomerIndex. \n",
    "\n",
    "This file contains the relation between customer indices and their real id values. First row of the file has field names (CustomerIndex and CustomerId) and the remaining rows contain customers' information, one at a time. The file has the following form:\n",
    "\n",
    "    CustomerIndex   CustomerId\n",
    "    0               516096\n",
    "    1               1\n",
    "    2               2793468\n",
    "    3               3006459\n",
    "\n",
    "CustomerIndex values will be used to determine each customer, so they should be unique and the values should start from 0 and go one by one.   \n",
    "\n",
    "#### ItemMapping.txt\n",
    "Similar to customers, we need to represent items with sequential numbers (namely ItemIndex). Also for some functions, we are planning to use the group information of the items, therefore we need the relation between items and the groups they belong to.\n",
    "\n",
    "This file has the following form:\n",
    "\n",
    "    ItemIndex\tItemId\tItemG3Index\tItemG3Id\tItemG3Ds\t        ItemDs\t\n",
    "    0\t        32823\t 0\t        470\t        Tereyağlar\t        SUTAS PASTORIZE \n",
    "    1\t        32867\t 1\t        457\t        Paketli Sosisler\tANTRIKOT SOSIS 400GR\n",
    "    2\t        32874\t 2\t        526\t        Toz Tatlılar\t    DR.OETKER 115GR\n",
    "    24\t        32970\t-1\t        -1\t        Invalid Item\t    BIBER KOY KG\n",
    "    \n",
    "In the provided dataset, some items do not have group information. We represent these items' ItemG3Index and ItemG3Id values as \"-1\" and IremG3Ds value as \"Invalid Item\". \n",
    "    \n",
    "ItemIndex and ItemG3Index values will be used to determine items. ItemIndex values should be unique and the values should start from 0 and go one by one. ItemG3Index values should be unique to each item group and the values should start from 0 and go one by one (except the invalid items). \n",
    "\n",
    "#### SalesTensor.txt\n",
    "This file contains the sales record of customers for a time period and has the following form:\n",
    "\n",
    "    WeekIndex\tDowIndex\tHourIndex\tItemIndex\tItemG3Index\t CustomerIndex\tAmount\t\n",
    "    0\t        0\t        13\t        477\t        -1\t         404\t        13.50\n",
    "    0\t        0\t        13\t        2847\t    103\t         404\t        11.95\n",
    "    0\t        0\t        13\t        5250\t    104\t         404\t        2.00\n",
    "    42\t        2\t        6\t        4474\t    139\t         3268\t        1.75\n",
    "    42\t        2\t        6\t        2516\t    31\t         3268\t        2.25\n",
    "    42\t        2\t        6\t        3277\t    50\t         3268\t        9.95\n",
    "    \n",
    "In the above example, some sales of customers whose indices are 404 and 3268 are displayed. Each entry contains the time, item, customer, and price information. \n",
    "\n",
    "WeekIndex, DowIndex and HourIndex values are determined by setting a fixed starting date for the sales at Obase Version 1. By looking at the first entry of the above example, we can say customer with index 404 bought item with index 477 (which does not have group information) at the starting week, Monday at 13h00. \n",
    "\n",
    "### Database Structure\n",
    "The database of Obase Version 2 will have the following structure (except weblog information of customers):\n",
    "\n",
    "<img src=\"otherFiles/newDb.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%writefile GenerateFilesForSql.py\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import *\n",
    "\n",
    "def generateCustomerMapping(filename,outfilename,fieldnames):\n",
    "    index = []\n",
    "    data = []\n",
    "\n",
    "    with open(filename) as inFile:\n",
    "        for row, entry in enumerate(inFile, 0):\n",
    "            index.append(int(row))\n",
    "            data.append(int(entry))\n",
    "    \n",
    "    index = np.array(index)\n",
    "    data = np.array(data)\n",
    "            \n",
    "\n",
    "    with open(outfilename, 'w') as outFile:\n",
    "        #for i in range(len(fieldnames)):\n",
    "        #    outFile.write('%s\\t' % fieldnames[i])\n",
    "        #outFile.write('\\n')\n",
    "        \n",
    "        for i in range(len(index)):\n",
    "            outFile.write('%d\\t %d\\n' % (index[i],data[i]))\n",
    "            \n",
    "            \n",
    "def generateItemMapping(filename,filenameDs,outfilename,fieldnames):\n",
    "    index = []\n",
    "    itemId = []\n",
    "    itemDs = []\n",
    "    itemIdG3 = []\n",
    "    itemDsG3 = []\n",
    "    \n",
    "    with open(filename) as inFile:\n",
    "        for row, entry in enumerate(inFile, 0):\n",
    "            index.append(int(row))\n",
    "            itemId.append(int(entry))\n",
    "    \n",
    "    with open(filenameDs) as inFile:\n",
    "        for row, entry in enumerate(inFile, 0):\n",
    "            itemDs.append(entry)\n",
    "\n",
    "    index = np.array(index)\n",
    "    itemId = np.array(itemId)\n",
    "    \n",
    "    num = 0\n",
    "    num2 = 0\n",
    "    for i in range(len(itemId)):\n",
    "        r = requests.get('http://212.57.2.68:93/api/database/urun?$select=IdUrunGrup3&$filter=IdUrun+eq+%d' % itemId[i])\n",
    "        tempId = r.json()\n",
    "        \n",
    "        if len(tempId) == 0 or tempId[0]['IdUrunGrup3'] is None:\n",
    "            tempId = -1\n",
    "            tempDs = 'Invalid Item'\n",
    "            num = num+1\n",
    "        else:\n",
    "            tempId = int(tempId[0]['IdUrunGrup3'])\n",
    "\n",
    "            r = requests.get('http://212.57.2.68:93/api/database/urungrup3?$select=DsUrunGrup3&$filter=IdUrunGrup3+eq+%d' % tempId)\n",
    "            tempDs = r.json()\n",
    "\n",
    "            if len(tempDs) == 0 or tempDs[0]['DsUrunGrup3'] is None:\n",
    "                tempDs = 'Invalid Item'\n",
    "                num2 = num2 + 1\n",
    "            else:\n",
    "                tempDs = tempDs[0]['DsUrunGrup3']\n",
    "                \n",
    "        itemIdG3.append(int(tempId))\n",
    "        itemDsG3.append(tempDs)\n",
    "        \n",
    "    print('Number of Invalid Items: %d %d' %(num,num2))\n",
    "    \n",
    "    indexG3 = []\n",
    "    visited = []\n",
    "\n",
    "    for i in range(len(index)):\n",
    "        temp = itemIdG3[i]\n",
    "        \n",
    "        if int(temp) == -1:\n",
    "            indexG3.append(-1)\n",
    "        else:\n",
    "            if temp not in visited:\n",
    "                visited.append(temp)\n",
    "\n",
    "            idx = visited.index(temp)\n",
    "            indexG3.append(idx)\n",
    "\n",
    "    with open(outfilename, 'w', encoding='utf-8') as outFile:\n",
    "        #for i in range(len(fieldnames)):\n",
    "        #    outFile.write('%s\\t' % fieldnames[i])\n",
    "        #outFile.write('\\n')\n",
    "\n",
    "        for i in range(len(index)):\n",
    "            outFile.write('%d\\t %d\\t %d\\t %d\\t %s\\t %s' % (index[i],itemId[i],indexG3[i],itemIdG3[i],itemDsG3[i],itemDs[i]))\n",
    "            \n",
    "            \n",
    "def generateSalesTensor(filename,mappingfilename,outfilename,fieldnames):\n",
    "    weekIndex = []\n",
    "    dowIndex = []\n",
    "    hourIndex = []\n",
    "    itemIndex = []\n",
    "    itemG3Index = []\n",
    "    customerIndex = []\n",
    "    amount = []\n",
    "\n",
    "    itemMap = []\n",
    "    with open(mappingfilename) as inFile2:\n",
    "        for line2 in inFile2:\n",
    "            values2 = line2.split('\\t')\n",
    "            itemMap.append(values2[2])    \n",
    "\n",
    "    itemMap = itemMap[1:]\n",
    "\n",
    "    with open(filename) as inFile:\n",
    "        for line in inFile:\n",
    "            values = line.split('\\t')\n",
    "\n",
    "            weekIndex.append(values[0])\n",
    "            dowIndex.append(values[1])\n",
    "            hourIndex.append(values[2])\n",
    "            itemIndex.append(values[3])\n",
    "\n",
    "            itemG3Index.append(itemMap[int(values[3])])\n",
    "\n",
    "            customerIndex.append(values[4])\n",
    "            amount.append(values[5])\n",
    "\n",
    "    with open(outfilename, 'w', encoding='utf-8') as outFile:\n",
    "            #for i in range(len(fieldnames)):\n",
    "            #    outFile.write('%s\\t' % fieldnames[i])\n",
    "            #outFile.write('\\n')\n",
    "\n",
    "            for i in range(len(weekIndex)):\n",
    "                outFile.write('%s\\t %s\\t %s\\t %s\\t %s\\t %s\\t %s' % (weekIndex[i],dowIndex[i],hourIndex[i],itemIndex[i],itemG3Index[i],customerIndex[i],amount[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'originalFiles/81_7_24_7269_3392_Customers.txt'\n",
    "outfilename = 'txtFiles/CustomerMapping.txt'\n",
    "fieldnames = ['CustomerIndex', 'CustomerId']\n",
    "\n",
    "generateCustomerMapping(filename,outfilename,fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'originalFiles/81_7_24_7269_3392_Items.txt'\n",
    "filenameDs = 'originalFiles/81_7_24_7269_3392_ItemsDs.txt'\n",
    "outfilename = 'txtFiles/ItemMapping.txt'\n",
    "fieldnames = ['ItemIndex', 'ItemId', 'ItemG3Index', 'ItemG3Id', 'ItemG3Ds', 'ItemDs']\n",
    "\n",
    "generateItemMapping(filename,filenameDs,outfilename,fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'originalFiles/81_7_24_7269_3392_Tensor.txt'\n",
    "mappingfilename = 'txtFiles/ItemMapping.txt'\n",
    "outfilename = 'txtFiles/SalesTensor.txt'\n",
    "fieldnames = ['WeekIndex', 'DowIndex', 'HourIndex', 'ItemIndex', 'ItemG3Index', 'CustomerIndex', 'Amount']\n",
    "\n",
    "generateSalesTensor(filename,mappingfilename,outfilename,fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
